[{"content":"Stick figures can work for a lot of scenarios, but several of them interacting isn’t one of them. They tend to look very alike, not letting you differentiate them when you need to.\nKey takeaway: How to draw people. How to make them interact. Emotions, middle aged, young, old, different looks and body shapes.\nWorkshop setup — part of Drawing to communicate workshop series.\n1. Draw a human being (2 minutes) Tell your participants to draw as many humans they can. Rectangular body, feet, eyes and mouth will later help you understand which way your human is pointing.\n2. Draw emotions (3 minutes) Add as little details as possible. No emotions needed, skip the mouth and eye-brows.\nTell the participants to draw (30 seconds on each drawing)\nWithout emotion Happy Surprised Sad Angry 3. Draw different ages (3 minutes) Tell the participants to draw (1 minute on each drawing)\nA middle aged person\nA kid Kids have larger heads compared to body size, closer to square body and smaller arms and legs compared to body size.\nAn old person Add age appropriate accessories and maybe bend the body shape a little?\n4. Draw styles and body shapes (4 minutes) Draw as many hair and face styles you can (2 minutes) Draw as many body styles you can (2 minutes) 5. Interaction (3 minutes) Someone arguing or one person yelling at another Two people sitting by a desk, talking. 6. Draw a group of people (2 minutes) Skip details to draw groups. Make the body rectangles merge, and remove some arms and legs.\nDraw a group that is either happy, angry or confused That’s it! The third part of the workshop is done. You now know how to draw human beings and make them interact!\nIf you need help or want to discuss some aspects of this? Contact me on LinkedIn, or create an issue over at GitHub, and I’ll try to help you out.\n","permalink":"https://eklem.github.io/blog/posts/human-beings-and-interaction/","summary":"Stick figures can work for a lot of scenarios, but several of them interacting isn’t one of them. They tend to look very alike, not letting you differentiate them when you need to.\nKey takeaway: How to draw people. How to make them interact. Emotions, middle aged, young, old, different looks and body shapes.\nWorkshop setup — part of Drawing to communicate workshop series.\n1. Draw a human being (2 minutes) Tell your participants to draw as many humans they can.","title":"Human beings and interaction — Get your people to interact"},{"content":"Things are actually going according to plan. Automatic indexing is up and running, and search is working, so now it’s time for a search information model. A search information model is kind of the information architecture of a search solution. The difference is that a good search engine revolves around the user more than a web page structure. You mold your information architecture to best fit your user, even if this doesn’t match the underlying architecture fully. The search information model will be the basis of the user experience, web design and front end code. A good reason a search solution has to revolve around the user, is that a user types in his/her words. If you ever see a search log, you’ll notice you’re looking at a users intention.\nAbove is the search information model so far. One example where the search information model doesn’t match the information architecthure is the user category. I don’t have any documents matching users, but I’ll agregate and consolidate so it will be one in the search solution. A user will then possibly consist of the following elements:\nName Email address Phone number gravatar photo/icon User names/IDs for: Twitter Instagram Flickr GitHub This will, in adition to a regular search, give me a per user search. I can search, find a user, click on that user and instead of going to a document that doesn’t exist, I can get a special search page for this person. I’ll be able to do something similar for “Events”, where I can show all results near (in time) a calendar or position event. All data is gathered by IFTTT IF-recipes and stored in spreadsheets in Google Drive. At the beginning of the project, I made a lot if IFTTT-recipes. Just by looking at the spreadsheets it was easy to figure out which sources were useful and which were not. A task manager called Remember the Milk seemd like a nice source to index, but looking at the data gathered, I understood it would only add noice. Nothing there triggered any re-finding nerve, which this search is all about: Indexing stuff, or actions/reactions, that I want to find back to and revisit at a later time. SMS’es also looked like a nice source for indexing, but when looking at the SMS’es stored, it was just to creepy to add to a search index. Also some sources are not that good because of limitations in IFTTT. One example is Facebook status message. It doesn’t have an item ID. That means I can’t link back to the actual message. But Facebook links and replies are okay.\nDocument preview and search engines Ok search solutions have document previews. You need a preview since a lot of the documents are not web formats. These previews are either images of a front page, or an HTML template faking the document layout. Either way, it’s not very interactive. It’s a display of what you might see if you take the time to click on the document and wait for it to open. Not so with Personal Search. The idea is to have a regular search result column in center, and actual content to the left. If I click/hover on an interesting tweet search result, I’ll get the full discussion thread to the left with all the interaction of Twitter to continue the discussion. All this with a message ID and an developer API.\nWhat’s now and what’s next? A Raspberry Pi running Norch\nAutomated indexing is working, and so is searching. I get a lot of duplicates, so will switch from using Norch-indexer to Search-index’ si.add function to get a more fine graind control when indexing documents. Anyhow, that’s fairly straight forward.\nSearch is working. Not looking pretty, and missing a lot of functional stuff. But working facets and all, and that’s great! It’s running of a Raspberry Pi 2 with Raspbian (Debian Wheezy) and it’s lightning fast. The first Raspberry Pi B was fast enough to handle search queries and deliver search results, but it’s a little underpowered for the indexing task. That leaves me with what’s next. First off, I’m going to make some quick interaction designs and create a static HTML prototype. The prototype will be a fork of the Norch-bootstrap repository and become Personal Search to quickly start creating a better frontend. In between there will be more code added to the document processing tool: IFTT-Norch-tools.\nUnfiltered search showing available filters for search query\nSearch result filtered on facet\nLast time, it was only an idea. Now search and facets are working nicely. More to come =)\n","permalink":"https://eklem.github.io/blog/posts/personal-search-information-model/","summary":"Things are actually going according to plan. Automatic indexing is up and running, and search is working, so now it’s time for a search information model. A search information model is kind of the information architecture of a search solution. The difference is that a good search engine revolves around the user more than a web page structure. You mold your information architecture to best fit your user, even if this doesn’t match the underlying architecture fully.","title":"Personal search information model"},{"content":"What if you could index your whole life and make this lifeindex available through search? What would that look like, and how could it help you? Refinding information is obviously one of the use case for this type of search. I’m guessing there’s a lot more, and I’m curious to figure them out.\nActions and reactions instead of web pages I had the lifeindex idea for a little while now. Originally the idea was to index everything I browsed. From what I know and where Norch is, it would take a while before I was anywhere close to achieving that goal. Then I thought of IFTTT, and saw it as a ‘next best thing’. But then it hit me that now I’m indexing actions, and that’s way better than pages. And the indexing process is event driven. But what I’m missing from most sources now are the reactions to my actions. If I have a question, I also want to crawl and index the answer. If I have a statement, I want to get the critique indexed.\nIFTTT and similar services (like Zapier) is quite limiting in their choice of triggers. Not sure if this is because of choices done by those services or limitations from the sites they crawl/pull information from.\nA quick fix for this, and a generally good idea for Search Engines, would be to switch from a preview of your content to the actual content in the form of an embed-view.\nTechnology: Hello IFTTT, Google SpreadSheet and Norch IFTTT is triggered by my actions, and stores some data to a series of spreadsheets on Google Drive. These spreadsheets can deliver JSON. After a little document processing these JSON-files can be fed to the Norch-indexer.\nWhy hasn’t this idea popped up earlier? Search engines used to be hardware guzzling technology. With Norch, the “NOde seaRCH” engine, that has changed. Elasticsearch and Solr are easy and small compared to i.e. SharePoint Search, but still it needs a lot of hardware. Norch can run on a Raspberry Pi, and soon it will be able to run in your browser. Maybe data sets closer to small data is more interesting than big data?\nA Raspberry Pi running a Norch search enginge\nWhy using a search engine? It’s cheap and quick. I’m not a developer, and I’ll still be able to glue all these sources together. Search engines are often a good choice when you have multiple sources. IFTTT and Google SpreadSheet makes it even easier, normalising the input and delivering it as JSON.\nHow far in the process have I come? So far, I’ve set up a lot of triggers/sources at IFTTT.com:\nInstagram: When posting or liking both photos and videos. Flickr: When posting an image, creating a set or linking a photo. Google Calendar: When adding something to one of my calendars. Facebook: When i post a link, is tagged, post a status message. Twitter: When I tweet, retweet, reply or if somebody mentions me. Youtube: When I post or like a video. GitHub: When I create an issue, gets assigned to an issue or any issues that I part take in is closed. WordPress: When new posts or comments on posts. Android location tracking: When I enter and exit certain areas. Android phone log: Placed, received and missed calls. Gmail: Starred emails. Data from different sources added to spreadsheets on Google Drive with IFTTT.\nAnd gotten a good chunk of data. Indexing my SMS’es felt a bit creepy, so I stopped doing that. And storing email just sounded too excessive, but I think starred emails would suit the purpose of the project.\nThose Google Drive documents are giving me JSON. Not JSON that I can feed directly Norch-indexer, it needs a little trimming.\nIssues discovered so far Manual work This search solution needs a lot of manual setup. Every trigger needs to be set up manually. Everytime a new trigger is triggered, I get a new spreadsheet that needs a title row added. Or else, the JSON variables will look funny, since first row is used for variable names.\nThe spreadsheets only accepts 2000 rows. After that a new file is created. Either I need to delete content, rename the file or reconfigure some stuff.\nLevel of maturity A lot of trigger timeout errors in the recipe log.\nIFTTT is a really nice service, and they treat their users well. But, for now, it’s not something you can trust fully.\nCleaning up duplicates and obsolete stuff I have no way of removing stuff from the index automatically at this point. If I delete something I’ve added/written/created, it will not be reflected in the index.\nMissing sources Books I buy, music I listen to, movies and TV-series I watch. Or Amazon, Spotify, Netflix and HBO. Apart from that, there are no Norwegian services available through IFTTT.\nHistory The crawling is triggered by my actions. That leaves me without history. So, i.e. new contacts on LinkedIn is meaningless when I don’t get to index the existing ones.\nNext steps JSON clean-up I need to make a document processing step. Norch-document-processor would be nice if it had handled JSON in addition to HTML. Not yet, but maybe in the future? Anyway, there’s just a small amount of JSON clean-up before I got my data in and index.\nWhen this step is done, a first version can be demoed.\nUX and front-end code To show the full potential, I need some interaction design of the idea. For now they’re all in my head. And these sketches needs to be converted to HTML, CSS and Angular view.\nEmbed codes Figure out how to embed Instagram, Flickr, Facebook and LinkedIn-posts, Google Maps, federated phonebook search etc.\nOAUTH configuration Set up OAUTH NPM package to access non-public spreadsheets on Google Drive. Then I can add some of the less open information I have stored.\n","permalink":"https://eklem.github.io/blog/posts/your-life-searchable/","summary":"What if you could index your whole life and make this lifeindex available through search? What would that look like, and how could it help you? Refinding information is obviously one of the use case for this type of search. I’m guessing there’s a lot more, and I’m curious to figure them out.\nActions and reactions instead of web pages I had the lifeindex idea for a little while now. Originally the idea was to index everything I browsed.","title":"Idea: Your life, searchable through Norch — NOde seaRCH"}]